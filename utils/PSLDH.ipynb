{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1., -1.,  1., -1.,  1., -1.],\n",
       "        [ 1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "          1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,\n",
       "          1.,  1., -1., -1.,  1.,  1., -1., -1.],\n",
       "        [ 1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "         -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "          1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "         -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "          1., -1., -1.,  1.,  1., -1., -1.,  1.],\n",
       "        [ 1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
       "        [ 1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "          1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "          1., -1.,  1., -1., -1.,  1., -1.,  1.],\n",
       "        [ 1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1., -1.,  1.,  1.],\n",
       "        [ 1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "          1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "          1., -1., -1.,  1., -1.,  1.,  1., -1.],\n",
       "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1.],\n",
       "        [ 1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1., -1.,  1., -1.,  1.]], device='mps:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import hash_model as image_hash_model\n",
    "import pickle\n",
    "\n",
    "top_k = 1000\n",
    "batch_size = 10\n",
    "epochs = 150\n",
    "learning_rate = 0.001 #0.05\n",
    "weight_decay = 10 ** -5\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.01\n",
    "lamda = 0.01 #50\n",
    "gamma = 0.2\n",
    "sigma = 0.2\n",
    "code_length = 64\n",
    "# 1. 加载CIFAR-10数据集\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "hash_bits = 64 # 假设哈希编码的位数\n",
    "model_name = \"vgg11\"\n",
    "device = torch.device(\"mps\")\n",
    "model = image_hash_model.HASH_Net(model_name, hash_bits)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.3, last_epoch=-1)\n",
    "\n",
    "# 3. 加载哈希编码\n",
    "with open('../labels/64_cifar10_10_class.pkl', 'rb') as f:\n",
    "    label_code = torch.load(f)\n",
    "label_code.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n",
      "torch.Size([10, 10])\n",
      "tensor([[ 5.6237e-01, -3.9726e-01,  5.2532e-01,  1.7990e-01,  6.6133e-01,\n",
      "          3.5797e-01,  3.8393e-01, -2.1520e-01, -4.8338e-01,  3.0614e-01,\n",
      "         -8.8840e-02,  2.9929e-01, -3.4418e-01,  2.8141e-01, -2.1158e-02,\n",
      "          3.3469e-01,  2.8631e-01, -4.8569e-01, -8.2876e-01,  1.9018e-01,\n",
      "          2.0906e-01, -4.7060e-01,  1.2424e-01,  2.0507e-01, -9.0063e-02,\n",
      "          2.0617e-01, -2.6634e-01, -3.0706e-01, -2.7210e-01, -1.7099e-01,\n",
      "          3.7904e-01,  5.7409e-01, -5.4631e-01,  3.4046e-02,  2.4665e-01,\n",
      "         -4.1593e-01,  1.5301e-01, -6.8084e-02, -7.7951e-01,  2.0936e-02,\n",
      "         -1.2844e-01, -1.2406e-01, -3.2081e-01, -2.4034e-01, -3.8700e-01,\n",
      "         -1.5146e-03,  1.3396e-01,  5.2997e-01, -5.4221e-01,  1.8010e-01,\n",
      "          3.5549e-01,  2.2619e-01, -4.5382e-01,  5.9925e-01, -2.0092e-01,\n",
      "         -1.6110e-01, -5.1936e-01, -4.0850e-01,  1.8207e-01, -7.8246e-01,\n",
      "         -2.3313e-01,  7.5020e-01, -1.1187e-01, -3.7288e-02],\n",
      "        [-5.7884e-01, -1.1137e-01, -3.0131e-01, -2.6044e-01,  7.5769e-01,\n",
      "         -1.5324e-01,  1.8468e-01, -1.0264e-01,  4.1151e-01,  3.9391e-03,\n",
      "          7.9006e-01, -3.9920e-01,  3.6281e-01,  4.7240e-02,  2.9884e-01,\n",
      "          1.1313e-01, -2.1835e-01, -9.2805e-02,  8.1637e-03, -2.4461e-01,\n",
      "          8.0723e-02, -8.6615e-01, -2.6381e-01,  1.6865e-01,  7.1658e-01,\n",
      "          8.4760e-02,  6.9628e-01, -2.6595e-01, -2.8229e-01,  4.8458e-02,\n",
      "         -1.5016e-01,  1.1113e-01, -6.1712e-02,  1.8488e-01,  5.2416e-01,\n",
      "         -5.8642e-01, -2.6155e-01,  3.5722e-01, -7.9102e-01,  5.8525e-02,\n",
      "          3.0542e-01, -4.0319e-01,  4.0971e-01, -1.8496e-01,  1.1684e-01,\n",
      "         -2.8566e-01,  6.6250e-01,  2.4928e-01, -4.9360e-01,  4.0725e-01,\n",
      "         -4.7530e-02,  2.6239e-01, -2.8052e-01,  8.1321e-01, -1.5861e-01,\n",
      "          4.6380e-01,  1.1462e-01,  2.9682e-02, -2.0332e-01,  7.1888e-01,\n",
      "         -2.1925e-01,  6.8617e-01,  5.0310e-01, -1.1894e-01],\n",
      "        [ 1.0504e-02,  3.8998e-01, -5.6554e-01,  1.2816e-01,  1.4776e-01,\n",
      "          5.4281e-01,  4.3937e-02, -3.4100e-01, -8.1271e-01, -1.9401e-01,\n",
      "         -3.0251e-01, -7.1543e-02,  5.4223e-02,  2.4707e-01,  3.9616e-01,\n",
      "         -1.1038e-01, -6.2812e-01,  2.7191e-01, -5.8243e-01, -4.1160e-01,\n",
      "          4.1068e-01, -4.4227e-01, -6.4567e-02, -4.6759e-01,  1.0048e-01,\n",
      "          3.5832e-01,  1.2232e-01, -5.3562e-01, -1.8844e-01,  3.3321e-01,\n",
      "         -3.3356e-01, -9.0863e-02,  2.2351e-01,  3.3265e-01,  5.8478e-02,\n",
      "         -6.5801e-01, -4.9580e-01,  8.2334e-03, -4.4257e-01, -6.8363e-02,\n",
      "         -2.3838e-01,  6.9407e-02, -4.5345e-01, -4.7477e-01, -7.1789e-01,\n",
      "         -2.9480e-01, -3.1370e-02,  4.9102e-01, -7.4259e-01, -2.1678e-01,\n",
      "         -2.4322e-01,  2.5925e-01, -3.0617e-01,  1.3360e-01, -4.8987e-01,\n",
      "         -1.2142e-01,  7.4457e-02,  3.5203e-01, -5.1525e-01, -3.8783e-01,\n",
      "          4.0994e-01,  3.6436e-01,  2.0719e-01,  1.0705e-01],\n",
      "        [-3.2375e-02,  1.7706e-01, -8.2410e-03, -5.6733e-03,  5.2951e-01,\n",
      "          4.4602e-01,  5.3501e-01,  5.8427e-01,  3.2908e-01, -2.5928e-01,\n",
      "          6.0820e-01,  1.6798e-01,  6.3643e-02,  2.3689e-01,  4.5018e-01,\n",
      "          6.4778e-01,  3.3928e-01,  1.7097e-01,  7.9404e-02,  7.5736e-01,\n",
      "         -8.3132e-02, -4.7839e-01,  3.8330e-01,  2.3464e-01, -2.6735e-01,\n",
      "         -3.1276e-01, -2.8543e-01,  1.4791e-01, -7.7357e-02, -1.3190e-01,\n",
      "         -3.8649e-01, -5.5262e-01, -1.4809e-01,  1.6826e-01, -1.9775e-02,\n",
      "         -4.1938e-01,  3.8932e-01,  1.7805e-01, -6.2353e-01,  5.3810e-01,\n",
      "         -1.5851e-01,  5.5174e-01,  3.1442e-01,  2.6722e-01,  3.3486e-01,\n",
      "          3.1139e-01,  4.4721e-01,  7.7710e-03, -1.4749e-01, -2.4147e-01,\n",
      "         -5.2109e-01,  2.1582e-01,  3.6287e-01,  2.7366e-01, -2.8813e-01,\n",
      "         -1.3940e-01,  5.2807e-01,  2.9238e-01, -5.0706e-01,  2.9206e-01,\n",
      "         -1.5320e-01,  6.2660e-01,  1.2755e-01,  1.0507e-01],\n",
      "        [-6.2380e-01,  5.5383e-02, -5.2218e-01,  5.0908e-01,  2.9441e-01,\n",
      "          1.4523e-01,  6.8763e-01,  5.1338e-01, -8.0405e-01, -1.2996e-01,\n",
      "          2.2913e-01, -6.1138e-01, -3.3435e-01,  5.1166e-01,  3.0354e-01,\n",
      "          4.6444e-01,  4.1883e-01,  4.5548e-01, -2.0223e-01, -3.3141e-02,\n",
      "          8.6912e-02, -3.1927e-01, -1.8671e-02, -5.2039e-01, -7.7511e-02,\n",
      "         -4.3046e-01,  6.0854e-01, -3.1545e-01,  6.0402e-01, -5.6879e-01,\n",
      "          4.0416e-01, -1.4785e-01,  3.4479e-01,  4.2323e-01, -8.5600e-02,\n",
      "          2.4466e-01, -3.9238e-01,  4.4199e-01, -7.0299e-01,  4.3847e-01,\n",
      "          7.3130e-02, -7.5154e-01,  9.7367e-02, -1.1137e-01, -5.8436e-01,\n",
      "         -3.7605e-01, -2.3590e-01, -6.2623e-02, -7.1458e-01, -7.9018e-01,\n",
      "          9.0694e-02,  7.2289e-01, -7.3330e-01,  9.4395e-01,  4.8886e-01,\n",
      "          4.1651e-01, -4.1566e-01, -3.2678e-01, -1.3450e-01, -2.9236e-01,\n",
      "          5.3313e-01,  7.6364e-01,  3.3049e-01, -1.7426e-01],\n",
      "        [ 2.1007e-01, -1.6011e-01, -1.8806e-01,  2.5771e-01,  5.7552e-01,\n",
      "          3.9914e-01,  1.3179e-01, -3.5148e-01, -1.1909e-01,  2.6787e-01,\n",
      "         -3.6312e-04,  2.4418e-01, -3.9668e-01,  2.7652e-01,  1.4980e-01,\n",
      "          1.9587e-02,  2.3432e-01,  4.1234e-02, -1.6218e-01, -3.7112e-01,\n",
      "         -4.1988e-02, -3.3521e-01,  1.8617e-01, -3.3160e-01,  2.7698e-01,\n",
      "         -6.5304e-02, -9.7459e-02,  6.7066e-02, -2.6566e-01,  7.6043e-01,\n",
      "          2.3149e-01, -2.1745e-02,  4.3312e-01,  1.1143e-01,  6.1688e-01,\n",
      "         -5.5219e-01, -1.8943e-01, -3.3211e-02, -3.5995e-01,  2.0097e-01,\n",
      "          1.6818e-01, -1.9592e-01, -9.6979e-02, -4.6527e-02, -4.0450e-01,\n",
      "          2.4356e-01, -1.3084e-01,  4.3948e-01, -3.8633e-01, -6.9071e-02,\n",
      "          3.7639e-01, -4.9878e-01, -3.6208e-01,  4.2609e-01,  3.4414e-01,\n",
      "          2.6953e-01, -3.4383e-01, -3.5984e-01, -3.3525e-01, -2.6841e-01,\n",
      "          2.1275e-01,  6.2750e-02,  1.3967e-01, -1.8490e-01],\n",
      "        [ 6.2903e-01,  6.0176e-01,  4.7742e-01,  1.6954e-01,  5.0898e-01,\n",
      "         -7.4911e-01,  5.4114e-01, -1.0153e-01,  4.1030e-02,  4.5024e-02,\n",
      "         -3.0799e-01,  3.5814e-01,  4.4052e-01,  1.0339e-01, -4.5874e-01,\n",
      "          7.0299e-02, -2.9652e-01,  3.3688e-01, -2.9937e-01, -2.7786e-01,\n",
      "          4.3086e-01, -5.8880e-03, -2.5482e-01, -2.4194e-01,  6.2363e-02,\n",
      "          2.3399e-01,  2.7152e-01, -7.6117e-01, -1.0937e-01, -4.7879e-01,\n",
      "         -3.2500e-01,  6.1040e-01, -1.7473e-01, -2.9228e-03, -7.7933e-03,\n",
      "          1.1563e-01,  6.0971e-01, -5.1179e-02, -4.8843e-01, -2.9503e-01,\n",
      "         -2.6815e-01, -2.6437e-01,  5.8854e-02,  7.2174e-02, -5.4589e-01,\n",
      "          2.0467e-01,  1.2277e-01,  3.0718e-01, -2.9119e-01, -3.0973e-01,\n",
      "          1.7711e-01,  8.5690e-02, -6.8619e-01,  7.2507e-01,  3.2572e-01,\n",
      "          2.1254e-01, -3.9122e-02,  6.5604e-01,  4.6693e-02,  8.3293e-02,\n",
      "         -5.5501e-01,  7.6863e-01,  1.4808e-01, -3.0730e-01],\n",
      "        [ 4.6643e-04, -6.8195e-01, -5.8894e-01, -4.5700e-01,  9.7969e-02,\n",
      "         -4.0003e-01, -1.2365e-01, -5.7433e-01, -3.8465e-01, -6.4071e-01,\n",
      "          4.9215e-01,  5.4666e-02,  1.3862e-01,  1.4345e-01,  6.2332e-01,\n",
      "          2.5718e-01,  6.3081e-01,  6.2256e-02, -3.3489e-01,  3.6868e-01,\n",
      "          3.1243e-01, -2.2513e-01,  1.1585e-01,  1.4574e-01,  2.8968e-01,\n",
      "          4.2156e-02, -2.4633e-01,  1.6199e-01, -7.0523e-01,  4.3488e-02,\n",
      "          4.6391e-01, -1.2693e-01,  1.8570e-01,  1.8398e-01, -2.3020e-01,\n",
      "         -3.0289e-01,  4.2588e-01, -2.5909e-01, -6.3433e-01, -5.8824e-01,\n",
      "         -3.7432e-01, -1.8394e-01,  5.5379e-01,  1.2661e-01,  2.6563e-02,\n",
      "          5.0410e-01,  5.9822e-01,  4.0449e-01, -2.3224e-01, -1.8120e-01,\n",
      "         -9.4044e-02, -4.2371e-02, -6.7461e-02,  4.5636e-02, -2.3961e-01,\n",
      "          6.5675e-01, -4.2956e-02,  4.1789e-01,  2.8378e-01,  1.0239e-01,\n",
      "          7.7318e-01,  2.4641e-01, -9.7473e-02,  9.2236e-02],\n",
      "        [-9.8221e-02,  3.0623e-01, -4.3270e-01, -3.7597e-01,  7.1988e-01,\n",
      "          6.2998e-01,  6.5638e-01,  4.2272e-01,  4.4433e-01,  5.9233e-01,\n",
      "          6.0442e-01, -1.9690e-01,  7.1537e-01,  4.2223e-01,  5.5629e-01,\n",
      "         -1.4357e-01,  4.0106e-01, -4.3303e-01, -2.3399e-01, -6.5164e-02,\n",
      "          2.2049e-01, -1.8093e-01, -1.6521e-01,  4.2223e-02,  1.3264e-01,\n",
      "          3.2723e-01,  3.9119e-01, -5.7415e-01, -4.3341e-01, -5.5794e-01,\n",
      "         -1.4907e-01,  4.0751e-01, -5.9257e-01, -4.1837e-01, -4.1869e-01,\n",
      "          5.6571e-01, -2.2134e-01, -8.7175e-02, -1.8156e-01, -8.5980e-01,\n",
      "          7.2889e-02,  5.7477e-01,  1.1700e-01, -4.3474e-03,  1.2961e-02,\n",
      "         -1.3655e-01,  4.5755e-01,  4.4376e-01,  4.3882e-01, -6.7794e-02,\n",
      "          2.9123e-01,  3.8006e-01,  3.8610e-02, -4.2316e-01, -7.3940e-01,\n",
      "          5.1120e-01, -7.4907e-02, -6.0229e-01, -2.5027e-01, -2.3391e-01,\n",
      "         -3.8539e-01,  3.5173e-01,  1.4349e-02, -5.2025e-01],\n",
      "        [ 1.2347e-02, -2.4827e-01,  2.6448e-01,  2.7132e-01,  6.5822e-01,\n",
      "         -7.2758e-02, -4.3527e-02,  2.7429e-01, -5.6132e-01,  5.0239e-02,\n",
      "          6.6157e-01,  3.0696e-01, -4.8607e-01,  3.8267e-02,  6.9063e-01,\n",
      "         -6.1872e-01, -2.2352e-01, -2.8038e-01, -3.9823e-01,  5.5759e-01,\n",
      "         -1.8519e-01, -2.2340e-01,  1.2814e-01, -2.8739e-01,  3.8330e-01,\n",
      "         -3.8525e-01,  2.2341e-01, -8.0367e-01,  2.3145e-02,  5.7566e-02,\n",
      "          2.0616e-01,  9.9578e-02,  6.7219e-01, -1.1028e-01, -7.4031e-02,\n",
      "          2.6298e-01, -4.7658e-01,  3.0547e-01, -2.1776e-01,  5.3529e-02,\n",
      "         -3.7017e-01,  3.5319e-01,  4.6893e-01,  5.2912e-01, -4.6348e-01,\n",
      "          5.2836e-01,  5.2353e-01,  4.6040e-01, -4.5189e-02,  4.2254e-01,\n",
      "          4.3232e-02,  3.0905e-01, -2.6033e-01,  1.8897e-01, -5.3903e-01,\n",
      "          4.2218e-01, -2.6387e-01, -3.7727e-01, -7.4707e-01,  1.9342e-01,\n",
      "          3.5423e-02,  5.5517e-01,  4.6999e-01, -2.9838e-01]], device='mps:0',\n",
      "       grad_fn=<TanhBackward0>)\n",
      "tensor([[-1.4259e+00, -3.4049e+00, -1.6528e+00, -2.0281e+00, -4.9652e+00,\n",
      "          3.1709e+00, -5.5662e-01, -8.2605e-01,  1.2978e+00,  4.1578e+00],\n",
      "        [ 3.3648e+00,  1.8988e+00, -9.2387e-01, -2.4594e+00, -9.3548e-01,\n",
      "          3.9592e+00, -3.1040e-01, -3.0287e+00, -6.5712e+00, -6.2982e+00],\n",
      "        [-6.3926e+00, -5.3970e+00,  5.5069e+00, -4.5115e+00, -4.1732e+00,\n",
      "         -2.0150e+00,  2.4615e+00, -1.5819e+00, -2.2603e+00, -6.1413e-01],\n",
      "        [ 6.9728e+00, -2.7435e+00,  6.6389e-01,  2.3433e+00, -2.8263e+00,\n",
      "         -9.9085e-01, -8.5236e-01,  9.7385e-01, -5.5933e-01, -6.8266e-01],\n",
      "        [ 1.0172e-01, -2.0745e+00, -4.6562e+00, -2.6700e+00, -6.3008e+00,\n",
      "          1.4031e+00, -2.3195e+00,  2.1254e+00,  4.0256e+00, -8.3872e+00],\n",
      "        [ 6.4871e-01,  1.6447e-01,  1.2947e+00, -3.7025e+00, -2.6715e+00,\n",
      "          4.2039e+00,  9.0289e-01,  2.9466e+00,  1.9468e-01,  4.6656e+00],\n",
      "        [ 1.6970e+00, -2.1301e+00,  1.4426e+00, -1.9843e+00,  7.4556e-01,\n",
      "          4.1160e-03, -4.7543e-02, -2.4257e+00,  1.1287e+00,  4.1081e+00],\n",
      "        [ 1.0123e+00,  2.2197e+00, -6.2875e-01,  1.6946e+00, -3.1356e+00,\n",
      "         -4.6523e-01, -8.8410e-01,  7.6700e-01, -7.0632e+00,  7.2612e-01],\n",
      "        [ 2.0051e+00,  1.8124e+00,  1.3718e+00,  3.7552e-01, -8.7188e-01,\n",
      "          2.2336e-01,  1.5073e+00, -6.3136e-01, -2.7461e+00, -2.3402e+00],\n",
      "        [ 2.6437e+00, -2.4251e+00, -4.1416e+00, -2.2814e+00, -4.4902e-01,\n",
      "          4.1466e-01, -1.9399e+00,  5.0089e+00, -3.2242e-01, -2.6354e+00]],\n",
      "       device='mps:0', grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(logit)\n\u001b[1;32m     21\u001b[0m our_logit \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp((logit \u001b[38;5;241m-\u001b[39m sigma \u001b[38;5;241m*\u001b[39m code_length) \u001b[38;5;241m*\u001b[39m gamma) \u001b[38;5;241m*\u001b[39m labels\n\u001b[0;32m---> 22\u001b[0m mu_logit \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mexp(logit \u001b[38;5;241m*\u001b[39m gamma) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m labels))\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(the_batch, \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m+\u001b[39m our_logit\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m ((torch\u001b[38;5;241m.\u001b[39mlog(our_logit \u001b[38;5;241m/\u001b[39m mu_logit \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m labels))\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m labels\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     25\u001b[0m Bbatch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(hash_out)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 5. 训练网络\n",
    "for epoch in range(10):  # 循环遍历数据集多次\n",
    "    scheduler.step()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_r = 0.0\n",
    "    epoch_loss_e = 0.0\n",
    "    for iter, traindata in enumerate(trainloader, 0):\n",
    "        inputs, labels= traindata\n",
    "        labels = torch.squeeze(labels)\n",
    "        inputs =inputs.to(device)\n",
    "        labels = labels.type(torch.FloatTensor).to(device)\n",
    "        the_batch = 3\n",
    "        hash_out = model(inputs)\n",
    "        logit = hash_out.mm(label_code.t().to(device))\n",
    "        print(label_code.size())\n",
    "        print(logit.size())\n",
    "        print(hash_out)\n",
    "\n",
    "        print(logit)\n",
    "        \n",
    "        our_logit = torch.exp((logit - sigma * code_length) * gamma) * labels\n",
    "        mu_logit = (torch.exp(logit * gamma) * (1 - labels)).sum(1).view(-1, 1).expand(the_batch, labels.size()[1]) + our_logit\n",
    "        loss = - ((torch.log(our_logit / mu_logit + 1 - labels)).sum(1) / labels.sum(1)).sum()\n",
    "\n",
    "        Bbatch = torch.sign(hash_out)\n",
    "        regterm = (Bbatch - hash_out).pow(2).sum()\n",
    "        loss_all = loss / the_batch + regterm * lamda / the_batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_all.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss_all.item()\n",
    "        epoch_loss_e += loss.item() / the_batch\n",
    "        epoch_loss_r += regterm.item() / the_batch\n",
    "    print('[Train Phase][Epoch: %3d/%3d][Loss_i: %3.5f, Loss_e: %3.5f, Loss_r: %3.5f]' %\n",
    "            (epoch + 1, epochs, epoch_loss / len(trainloader), epoch_loss_e / len(trainloader),\n",
    "            epoch_loss_r / len(trainloader)))\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
